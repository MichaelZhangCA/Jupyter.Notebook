{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enterprise Deep Learning with TensorFlow: openSAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAP Innovation Center Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook makes use of Tensorflow's new Estimator API and the new Dataset API.\n",
    "Both APIs are widely used within Google. They simplify and standardize model building.\n",
    "\n",
    "The Estimator API.\n",
    "\n",
    "tf.estimator.Estimator:  \n",
    "An 'estimator' takes as input some 'model' function along with some custom parameters.  \n",
    "It wraps the training loop, evaluation loop & prediction stage.  \n",
    "  \n",
    "  def model_fn(features, labels, mode, params):  \n",
    "     ...\n",
    "     setup network graph for training, evaluation, and prediction mode  \n",
    "     define loss & training operator  \n",
    "     define what the network outputs / predicts  \n",
    "     define accuracy measures  \n",
    "  \n",
    "     return tf.estimator.EstimatorSpec(loss, mode, predictions, train_op, eval_metric_ops, training_hooks)  \n",
    "\n",
    "  estimator = tf.estimator.Estimator(model_fn, params, config)\n",
    "  \n",
    "  def train_input_fn():  \n",
    "      return features, labels   # tensors  \n",
    "  \n",
    "  estimator.train(train_input_fn)  \n",
    "  \n",
    "  \n",
    "  def validation_input_fn():  \n",
    "      return features, labels   # tensors  \n",
    "  \n",
    "  estimator.evaluate(validation_input_fn)  \n",
    "  \n",
    "  result = estimator.predict(predict_input_fn)  \n",
    "  \n",
    "  for output in result:  \n",
    "  \n",
    "      do_something_with(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our output/log directory\n",
    "LOG_DIR = './rnn_output'\n",
    "# The number of steps in each training sequence\n",
    "# (i.e. our sequence length)\n",
    "TIMESTEPS = 5\n",
    "# The number of hidden units in the RNN layer\n",
    "RNN_NUM_UNITS = 10\n",
    "# The number of hidden units in the two additional fully connected layers\n",
    "DENSE_LAYERS = [10, 10]\n",
    "# The number of training iterations\n",
    "TRAINING_STEPS = 10000\n",
    "# The number of training features we are going to train in parallel\n",
    "# (to speed things up)\n",
    "BATCH_SIZE = 100\n",
    "# How often do we want to do screen / file log output\n",
    "PRINT_STEPS = TRAINING_STEPS / 1000\n",
    "# Our learning rate\n",
    "# If too large, training can become unstable.\n",
    "# If too small, training might converge too slowly or not to an optimium.\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# The RunConfig object that is used by our Estimator (see below).\n",
    "# Among other things, this is useful for setting the output / logging directory\n",
    "# as well as the output frequency.\n",
    "run_config = tf.estimator.RunConfig()\n",
    "run_config = run_config.replace(model_dir=LOG_DIR, save_summary_steps=PRINT_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The raw data: This is simply a sine function, i.e. one long sequence\n",
    "# of scalar values.\n",
    "xx = np.linspace(0, 100, 10000)\n",
    "raw_data = np.sin(xx)\n",
    "\n",
    "# Let's split this into train/validation data\n",
    "# We take the first 80% of elements in the sequence\n",
    "# as training elements, and the remaining as validation elements.\n",
    "N = int(raw_data.shape[0] * 0.8)\n",
    "train_data = raw_data[:N]\n",
    "valid_data = raw_data[N:]\n",
    "\n",
    "# During training, we don't actually work on the entire sequence at once.\n",
    "# In most cases this would be computationally prohibitive.\n",
    "# Rather, we split up the sequence into many small sub-sequences.\n",
    "# One single input feature becomes a subsequence of N elements.\n",
    "# Based on that input sequence, the network shall learn to predict the next\n",
    "# element following that sequence.\n",
    "# The associated training label to any input sequence\n",
    "# therefore is the next value coming right after the last element in the input sequence.\n",
    "# This routine returns exactly that!\n",
    "# From large raw sequence [0,1,2,3,4,5,6,7,8,9], we get a list of subsequences with associated\n",
    "# label.\n",
    "#  E.g.  --->\n",
    "#  list of input features: [[0,1,2], [1,2,3], [2,3,4], ..., [6,7,8]]\n",
    "#  list of associated labels: [3, 4, 5, ..., 9]\n",
    "def make_rnn_data(data):\n",
    "\n",
    "    # 'data' is one large 1D numpy array.\n",
    "\n",
    "    # Make a list of 1D numpy arrays\n",
    "    features = [data[i:i + TIMESTEPS] for i in range(data.shape[0] - TIMESTEPS)]\n",
    "    # Make a list of scalars\n",
    "    labels = [data[i + TIMESTEPS] for i in range(data.shape[0] - TIMESTEPS)]\n",
    "\n",
    "    # Let's convert the lists to numpy arrays.\n",
    "    features = np.asarray(features)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This routine returns a (features, labels) tuple\n",
    "# of tensors. These tensors are fed by Tensorflow's dataset API using the\n",
    "# train_samples data set generated above.\n",
    "def train_input():\n",
    "\n",
    "    # Let's convert the raw training data to (features, label) pairs\n",
    "    features, labels = make_rnn_data(train_data)\n",
    "\n",
    "    num_training_samples = features.shape[0]\n",
    "\n",
    "    # We use the numpy feature, label arrays to generate a Tensorflow dataset.\n",
    "    # This dataset is a source of training samples\n",
    "    dataset = tf.contrib.data.Dataset.from_tensor_slices((tf.constant(features, dtype=tf.float32),\n",
    "                                                          tf.constant(labels, dtype=tf.float32)))\n",
    "\n",
    "    # Let's repeat samples from the dataset indefinitly\n",
    "    dataset = dataset.repeat()\n",
    "    # Let's shuffle training samples. This will improve training because the network will\n",
    "    # see individual training samples in random order and grouped in random batches.\n",
    "    dataset = dataset.shuffle(num_training_samples)\n",
    "    # Let's finally batch individual samples to groups of BATCH_SIZE samples\n",
    "    # This is what the network will receive as input.\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    # Finally, create a one shot iterator for the dataset.\n",
    "    # The iterator is used for accessing the individual elements from the dataset\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    # Get the shuffled and batched samples from the dataset\n",
    "    # This actually returns tensors.\n",
    "    features, labels = iterator.get_next()\n",
    "\n",
    "    return (features, labels)\n",
    "\n",
    "# Same as above, but for validation data.\n",
    "# Only some subtle differences\n",
    "def valid_input():\n",
    "\n",
    "    features, labels = make_rnn_data(valid_data)\n",
    "\n",
    "    dataset = tf.contrib.data.Dataset.from_tensor_slices((tf.constant(features, dtype=tf.float32),\n",
    "                                                          tf.constant(labels, dtype=tf.float32)))\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    # Note: we do not need to shuffle!\n",
    "\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    features, labels = iterator.get_next()\n",
    "\n",
    "    return (features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some TensorFlow helper classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputHook(tf.train.SessionRunHook):\n",
    "\n",
    "    def __init__(self, name, log_dir=None, logged_tensors={}, save_steps=100):\n",
    "\n",
    "        self._logdir = log_dir\n",
    "        self._logged_tensors = logged_tensors\n",
    "        self._save_steps = save_steps\n",
    "        self._name = name\n",
    "\n",
    "    def begin(self):\n",
    "        # Let's get the 'global_step' tensor.\n",
    "        # The Tensorflow estimator will create this tensor to log / control\n",
    "        # the training.\n",
    "        # We need it to know at which training step we are.\n",
    "        self._global_step_tensor = tf.train.get_global_step()\n",
    "        self._logged_tensors['step'] = self._global_step_tensor\n",
    "\n",
    "    def before_run(self, run_context):\n",
    "        \"\"\" This routine is executed by Tensorflow before each training step.\n",
    "            It returns a dictionary of tensors that shall be\n",
    "            evaluated by the actual training step (i.e. the implicit session.run call).\n",
    "        \"\"\"\n",
    "        return tf.train.SessionRunArgs(fetches=self._logged_tensors)\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "        \"\"\" This routine is run directly after a training step (i.e. a session.run call).\n",
    "            Since we returned a 'SessionRunArgs' object in the before_run routine above,\n",
    "            This routine will receive a dictionary of results of the evaluated tensors (in \"run_values\").\n",
    "            Here, we are interested in outputting those results to a text ascii file.\n",
    "        \"\"\"\n",
    "\n",
    "        if run_values.results['step'] % self._save_steps:\n",
    "            return\n",
    "\n",
    "        fp = open(self._logdir+'/'+self._name+'.txt', 'a')\n",
    "\n",
    "        fp.write(str(run_values.results['step']))\n",
    "        del run_values.results['step']\n",
    "\n",
    "        for key in run_values.results:\n",
    "            fp.write(' '+str(run_values.results[key]))\n",
    "        fp.write('\\n')\n",
    "        fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part defines our recurrent neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This routine sets up the network and defines the cost function / optimizer that\n",
    "# is used during training. It also defines what the network is actually predicting.\n",
    "# The 'features' and 'labels' arguments are mandatory. The remaining arguments are optional and can be used\n",
    "# to further control the behavior of this function.\n",
    "def rnn_model(features, labels, mode, params, config):\n",
    "\n",
    "    # Let's define a simple vanilla RNN \"cell\".\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicRNNCell(params['rnn_num_units'])\n",
    "\n",
    "    # Our input features are batches of entire sequences right now, ie.e matrices of shape [batch_size x sequence_length].\n",
    "    # However, the network needs to be unrolled and look at each element in the sequence sequentially.\n",
    "    # This is what happens here: from a tensor of shape [batch_size x sequence_length]\n",
    "    # we generate a list of tensors [[batch_size], .... ]\n",
    "    x_ = tf.unstack(features, params['timesteps'], axis=1)\n",
    "    # Even though each element in our sequence is just a batch of scalars at this stage (i.e. shape [batch_size]),\n",
    "    # Tensorflow wants us to still have the tensors of shape [batch_size x 1].\n",
    "    x_ = [ tf.reshape(x, (-1,1)) for x in x_ ]\n",
    "    # Let's actually create a RNN layer that is unrolled over the individual elements of the sequence.\n",
    "    output, layers = tf.nn.static_rnn(rnn_cell, x_, dtype=tf.float32)\n",
    "\n",
    "    # Let's also attach some final non-recurrent fully connected layers after the RNN  layer.\n",
    "    output = slim.fully_connected(output[-1], num_outputs=10, activation_fn=tf.nn.relu)\n",
    "    output = slim.fully_connected(output, num_outputs=10, activation_fn=tf.nn.relu)\n",
    "    # This is the finaly regression layer (no non-linearity!)\n",
    "    # It just contains one unit since we want to regress exactly one single scalar value.\n",
    "    output = slim.fully_connected(output, num_outputs=1, activation_fn=None)\n",
    "    # We need to remove the last axis which is of dimension 1 (due to the single unit in the last fully connected layer)\n",
    "    # i.e. tensor of shape [batch_size, 1] is transformed to a tensor of shape\n",
    "    # [batch_size]\n",
    "    # This is our final network output (a batch of scalars)\n",
    "    output = tf.squeeze(output)\n",
    "\n",
    "    train_op = None\n",
    "    loss = None\n",
    "\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        # This is the loss / cost function we aim to minimize!\n",
    "        # Since we want the network to learn to predict/regress the next element in the sequence,\n",
    "        # the loss is the mean squared distance between the label and the prediction (i.e. the network output)\n",
    "        loss = tf.losses.mean_squared_error(labels, output)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        print ('Setting up model for training mode!')\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        # Let's monitor the loss\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "    predictions = {\n",
    "        'prediction': output,\n",
    "    }\n",
    "    eval_metric_ops = None\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            \"accuracy\": tf.metrics.mean_squared_error(labels, predictions[\"prediction\"])\n",
    "        }\n",
    "        # Let's monitor the accuracy for evaluation\n",
    "        tf.summary.scalar('accuracy', eval_metric_ops['accuracy'])\n",
    "\n",
    "\n",
    "    training_hooks = []\n",
    "\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        summary = tf.summary.merge_all()\n",
    "        # This will create and write output summaries to Tensorboard\n",
    "        summary_hook = tf.train.SummarySaverHook(save_steps=config.save_summary_steps, summary_op=summary)\n",
    "        # Let's also use our custom output hook to write the training loss to ascii file\n",
    "        output_hook = OutputHook(name='training', log_dir=config.model_dir, logged_tensors={'loss' : loss}, save_steps=config.save_summary_steps)\n",
    "\n",
    "        training_hooks.append(summary_hook)\n",
    "        training_hooks.append(output_hook)\n",
    "\n",
    "    # The model function must return a EstimatorSpec object\n",
    "    # The EstimatorSpec object wraps the loss, train_op, hooks, etc...\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                      loss=loss,\n",
    "                                      train_op=train_op,\n",
    "                                      predictions=predictions,\n",
    "                                      eval_metric_ops=eval_metric_ops,\n",
    "                                      training_hooks=training_hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './rnn_output', '_tf_random_seed': None, '_save_summary_steps': 10.0, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000246E83EE9B0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From <ipython-input-4-aa31f1242146>:14: Dataset.from_tensor_slices (from tensorflow.contrib.data.python.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.from_tensor_slices()`.\n",
      "Setting up model for training mode!\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./rnn_output\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.50449, step = 1\n",
      "INFO:tensorflow:global_step/sec: 191.604\n",
      "INFO:tensorflow:loss = 0.034047, step = 101 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.851\n",
      "INFO:tensorflow:loss = 0.00559858, step = 201 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.476\n",
      "INFO:tensorflow:loss = 0.00101254, step = 301 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.179\n",
      "INFO:tensorflow:loss = 0.000476129, step = 401 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.011\n",
      "INFO:tensorflow:loss = 0.000373947, step = 501 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.856\n",
      "INFO:tensorflow:loss = 0.000361497, step = 601 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.648\n",
      "INFO:tensorflow:loss = 0.000318529, step = 701 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.546\n",
      "INFO:tensorflow:loss = 0.000257622, step = 801 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.202\n",
      "INFO:tensorflow:loss = 0.000238109, step = 901 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.609\n",
      "INFO:tensorflow:loss = 0.000176044, step = 1001 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.073\n",
      "INFO:tensorflow:loss = 0.000169042, step = 1101 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.533\n",
      "INFO:tensorflow:loss = 0.000107708, step = 1201 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.308\n",
      "INFO:tensorflow:loss = 0.000114884, step = 1301 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.634\n",
      "INFO:tensorflow:loss = 8.09068e-05, step = 1401 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.623\n",
      "INFO:tensorflow:loss = 7.42293e-05, step = 1501 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.718\n",
      "INFO:tensorflow:loss = 6.44833e-05, step = 1601 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.056\n",
      "INFO:tensorflow:loss = 4.70033e-05, step = 1701 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.059\n",
      "INFO:tensorflow:loss = 4.95341e-05, step = 1801 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.613\n",
      "INFO:tensorflow:loss = 6.15218e-05, step = 1901 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.919\n",
      "INFO:tensorflow:loss = 4.99418e-05, step = 2001 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.796\n",
      "INFO:tensorflow:loss = 5.2219e-05, step = 2101 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.8\n",
      "INFO:tensorflow:loss = 4.64688e-05, step = 2201 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.828\n",
      "INFO:tensorflow:loss = 5.46219e-05, step = 2301 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.94\n",
      "INFO:tensorflow:loss = 5.31348e-05, step = 2401 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.124\n",
      "INFO:tensorflow:loss = 4.84077e-05, step = 2501 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.636\n",
      "INFO:tensorflow:loss = 3.79698e-05, step = 2601 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.236\n",
      "INFO:tensorflow:loss = 3.88643e-05, step = 2701 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.767\n",
      "INFO:tensorflow:loss = 3.76232e-05, step = 2801 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.693\n",
      "INFO:tensorflow:loss = 3.80869e-05, step = 2901 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.5\n",
      "INFO:tensorflow:loss = 3.55134e-05, step = 3001 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.134\n",
      "INFO:tensorflow:loss = 4.28029e-05, step = 3101 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.296\n",
      "INFO:tensorflow:loss = 3.57875e-05, step = 3201 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.738\n",
      "INFO:tensorflow:loss = 2.75619e-05, step = 3301 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.778\n",
      "INFO:tensorflow:loss = 2.97488e-05, step = 3401 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.473\n",
      "INFO:tensorflow:loss = 3.17259e-05, step = 3501 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.387\n",
      "INFO:tensorflow:loss = 2.57029e-05, step = 3601 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.533\n",
      "INFO:tensorflow:loss = 2.44976e-05, step = 3701 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.042\n",
      "INFO:tensorflow:loss = 2.45112e-05, step = 3801 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.873\n",
      "INFO:tensorflow:loss = 2.27387e-05, step = 3901 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.885\n",
      "INFO:tensorflow:loss = 2.25029e-05, step = 4001 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.192\n",
      "INFO:tensorflow:loss = 2.0681e-05, step = 4101 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.763\n",
      "INFO:tensorflow:loss = 2.77637e-05, step = 4201 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.563\n",
      "INFO:tensorflow:loss = 1.88399e-05, step = 4301 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.726\n",
      "INFO:tensorflow:loss = 1.97281e-05, step = 4401 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.01\n",
      "INFO:tensorflow:loss = 1.58049e-05, step = 4501 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.112\n",
      "INFO:tensorflow:loss = 1.49074e-05, step = 4601 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.534\n",
      "INFO:tensorflow:loss = 2.4098e-05, step = 4701 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.045\n",
      "INFO:tensorflow:loss = 1.44238e-05, step = 4801 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.103\n",
      "INFO:tensorflow:loss = 1.78965e-05, step = 4901 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.484\n",
      "INFO:tensorflow:loss = 1.22807e-05, step = 5001 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.482\n",
      "INFO:tensorflow:loss = 2.17916e-05, step = 5101 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.444\n",
      "INFO:tensorflow:loss = 1.38409e-05, step = 5201 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.701\n",
      "INFO:tensorflow:loss = 2.88632e-05, step = 5301 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.078\n",
      "INFO:tensorflow:loss = 1.25333e-05, step = 5401 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.462\n",
      "INFO:tensorflow:loss = 1.63587e-05, step = 5501 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.854\n",
      "INFO:tensorflow:loss = 1.23427e-05, step = 5601 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.5\n",
      "INFO:tensorflow:loss = 1.65385e-05, step = 5701 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.704\n",
      "INFO:tensorflow:loss = 1.2556e-05, step = 5801 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.68\n",
      "INFO:tensorflow:loss = 1.11731e-05, step = 5901 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.505\n",
      "INFO:tensorflow:loss = 1.54745e-05, step = 6001 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.039\n",
      "INFO:tensorflow:loss = 9.6427e-06, step = 6101 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.343\n",
      "INFO:tensorflow:loss = 8.23994e-06, step = 6201 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.231\n",
      "INFO:tensorflow:loss = 9.9272e-06, step = 6301 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.196\n",
      "INFO:tensorflow:loss = 9.08492e-06, step = 6401 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.293\n",
      "INFO:tensorflow:loss = 1.68649e-05, step = 6501 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.667\n",
      "INFO:tensorflow:loss = 1.00002e-05, step = 6601 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.815\n",
      "INFO:tensorflow:loss = 9.04294e-06, step = 6701 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.647\n",
      "INFO:tensorflow:loss = 7.87961e-06, step = 6801 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.707\n",
      "INFO:tensorflow:loss = 7.84896e-06, step = 6901 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.958\n",
      "INFO:tensorflow:loss = 7.04705e-06, step = 7001 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.19\n",
      "INFO:tensorflow:loss = 5.5578e-06, step = 7101 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.341\n",
      "INFO:tensorflow:loss = 4.67131e-06, step = 7201 (0.322 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 279.447\n",
      "INFO:tensorflow:loss = 7.93688e-06, step = 7301 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.278\n",
      "INFO:tensorflow:loss = 4.82212e-06, step = 7401 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.332\n",
      "INFO:tensorflow:loss = 6.63166e-06, step = 7501 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.653\n",
      "INFO:tensorflow:loss = 5.69698e-06, step = 7601 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.059\n",
      "INFO:tensorflow:loss = 5.90446e-06, step = 7701 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.042\n",
      "INFO:tensorflow:loss = 7.75845e-06, step = 7801 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.084\n",
      "INFO:tensorflow:loss = 5.18153e-06, step = 7901 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.56\n",
      "INFO:tensorflow:loss = 6.42381e-06, step = 8001 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.091\n",
      "INFO:tensorflow:loss = 7.8959e-06, step = 8101 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.55\n",
      "INFO:tensorflow:loss = 4.96342e-06, step = 8201 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.534\n",
      "INFO:tensorflow:loss = 4.65022e-06, step = 8301 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.047\n",
      "INFO:tensorflow:loss = 7.70106e-06, step = 8401 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.421\n",
      "INFO:tensorflow:loss = 2.84342e-06, step = 8501 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.507\n",
      "INFO:tensorflow:loss = 4.52653e-06, step = 8601 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.245\n",
      "INFO:tensorflow:loss = 3.07764e-06, step = 8701 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.306\n",
      "INFO:tensorflow:loss = 4.41989e-06, step = 8801 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.621\n",
      "INFO:tensorflow:loss = 2.9139e-06, step = 8901 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.325\n",
      "INFO:tensorflow:loss = 6.50734e-06, step = 9001 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.896\n",
      "INFO:tensorflow:loss = 6.68938e-06, step = 9101 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.465\n",
      "INFO:tensorflow:loss = 3.97894e-06, step = 9201 (0.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.479\n",
      "INFO:tensorflow:loss = 2.55263e-06, step = 9301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.409\n",
      "INFO:tensorflow:loss = 3.85377e-06, step = 9401 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.508\n",
      "INFO:tensorflow:loss = 3.84458e-06, step = 9501 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.52\n",
      "INFO:tensorflow:loss = 2.54276e-06, step = 9601 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.145\n",
      "INFO:tensorflow:loss = 3.00238e-06, step = 9701 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.672\n",
      "INFO:tensorflow:loss = 8.93788e-06, step = 9801 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.917\n",
      "INFO:tensorflow:loss = 2.46748e-06, step = 9901 (0.345 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into ./rnn_output\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.55002e-06.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-08-04:20:16\n",
      "INFO:tensorflow:Restoring parameters from ./rnn_output\\model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-08-04:20:17\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 2.13712e-06, global_step = 10000, loss = 2.13706e-06\n",
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from ./rnn_output\\model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "# Let's setup our estimator!\n",
    "# An estimator requires a model function\n",
    "regressor = tf.estimator.Estimator(model_fn=rnn_model,\n",
    "                                   params={'learning_rate' : LEARNING_RATE,\n",
    "                                           'timesteps' : TIMESTEPS,\n",
    "                                           'rnn_num_units' : RNN_NUM_UNITS},\n",
    "                                   config=run_config)\n",
    "\n",
    "\n",
    "\n",
    "# Set the logging verbosity\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Execute the training using 'train_input' as the training input function!\n",
    "regressor.train(train_input, steps=TRAINING_STEPS)\n",
    "\n",
    "# Execute validation using 'valid_input' as the validation input function\n",
    "regressor.evaluate(valid_input)\n",
    "\n",
    "\n",
    "# Let's get a python generator of network prediction.\n",
    "# At this point, the network will not be evaluated!\n",
    "# It will only be evaluated once we explicitly ask for it!\n",
    "generator = regressor.predict(valid_input)\n",
    "\n",
    "# Let's open an ascii text file to write the predictions\n",
    "fp = open(LOG_DIR+'/prediction.txt', 'w')\n",
    "\n",
    "# Let's loop over the generator and get the results for each\n",
    "# sample in the validation set!\n",
    "results = []\n",
    "for i, result in enumerate(generator):\n",
    "\n",
    "    results.append(result[\"prediction\"])\n",
    "    fp.write(str(i+N+TIMESTEPS)+' '+str(result['prediction'])+'\\n')\n",
    "\n",
    "fp.close()\n",
    "\n",
    "\n",
    "fp = open(LOG_DIR+'/raw_data.txt', 'w')\n",
    "for i in range(raw_data.shape[0]):\n",
    "    fp.write(str(i)+' '+str(raw_data[i])+'\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
